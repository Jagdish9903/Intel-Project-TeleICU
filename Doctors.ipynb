{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e8c4d6-9752-4985-83b6-4a5487ee9e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e8662a-1c5c-4daa-9a6a-60de051d189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afde3ed-a743-410b-9e4b-a13df060dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Chrome webdriver\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a22fa-f7f1-46fc-bb94-e722bcee8140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(base_url, folder_path, total_pages=1):\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    img_count = 1\n",
    "\n",
    "    # Initialize the Chrome webdriver\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")  # Run Chrome in headless mode\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    try:\n",
    "        for page in range(1, total_pages + 1):\n",
    "            # Construct the URL for the current page\n",
    "            url = f\"{base_url}&page={page}\"\n",
    "            print(f\"Scraping page: {page}\")\n",
    "\n",
    "            # Load the page\n",
    "            driver.get(url)\n",
    "            time.sleep(2)  # Add a delay to allow time for the page to load dynamically\n",
    "\n",
    "            # Scroll down the page to load all images\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            while True:\n",
    "                # Scroll down to bottom\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "                # Wait to load page\n",
    "                time.sleep(2)\n",
    "\n",
    "                # Calculate new scroll height and compare with last scroll height\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "\n",
    "            # Extract the HTML content after all images have been loaded\n",
    "            html_content = driver.page_source\n",
    "\n",
    "            # Parse the HTML content\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "            # Find the div with class 'mui-1kkefsa-gridContainer-root'\n",
    "            grid_container = soup.find('div', class_='mui-1kkefsa-gridContainer-root')\n",
    "            if not grid_container:\n",
    "                print(f\"No images found on page {page}\")\n",
    "                continue\n",
    "\n",
    "            # Find all divs with the specified data-automation attribute\n",
    "            divs = grid_container.find_all('div', {'data-automation': 'AssetGrids_GridItemContainer_div'})\n",
    "            if not divs:\n",
    "                print(f\"No images found on page {page}\")\n",
    "                continue\n",
    "\n",
    "            # Download and save each image\n",
    "            for div in divs:\n",
    "                picture = div.find('picture')\n",
    "                if picture:\n",
    "                    img_tag = picture.find('img')\n",
    "                    if img_tag and img_tag['src']:\n",
    "                        img_url = img_tag['src']\n",
    "                        try:\n",
    "                            img_data = requests.get(img_url).content\n",
    "                            img_name = f\"img{img_count}.jpg\"\n",
    "                            img_path = os.path.join(folder_path, img_name)\n",
    "                            with open(img_path, 'wb') as f:\n",
    "                                f.write(img_data)\n",
    "                            print(f\"Downloaded {img_name} from {img_url}\")\n",
    "                            img_count += 1\n",
    "                        except Exception as e:\n",
    "                            print(f\"Failed to download image from {img_url}: {e}\")\n",
    "    finally:\n",
    "        # Close the webdriver\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f320ed-af8e-4e92-a9c7-8e36f7838a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Base URL of the website with the images (excluding the page parameter)\n",
    "# base_url = \"https://www.shutterstock.com/search/icu-doctor-patient?image_type=photo&mreleased=true&orientation=horizontal\"\n",
    "# # Folder path to save the images\n",
    "# folder_path = \"DoctorImages\"\n",
    "\n",
    "# # Total number of pages to scrape\n",
    "# total_pages = 11\n",
    "\n",
    "# # Call the function to download images\n",
    "# download_images(base_url, folder_path, total_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac919b6-13c7-4a9a-bb6c-9273de898260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL of the website with the images (excluding the page parameter)\n",
    "base_url = \"https://www.shutterstock.com/search/doctor-and-patient-in-icu?mreleased=true\"\n",
    "# Folder path to save the images\n",
    "folder_path = \"DoctorImages\"\n",
    "\n",
    "# Total number of pages to scrape\n",
    "total_pages = 13\n",
    "\n",
    "# Call the function to download images\n",
    "download_images(base_url, folder_path, total_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba2b6c-0a2a-4029-a9c8-775fb480212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading labelImg\n",
    "\n",
    "# !pip3 install labelImg\n",
    "import labelImg\n",
    "!labelImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16536c3b-5113-4650-839b-4a8c95a86f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def convert_to_yolo_format(json_dir, images_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for json_file in os.listdir(json_dir):\n",
    "        # if json_file.endswith('.json'):\n",
    "        with open(os.path.join(json_dir, json_file)) as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        image_filename = data['task']['data']['image'].split('=')[1].replace('%5C', '/')\n",
    "        print(image_filename)\n",
    "        image_path = os.path.join(image_filename)\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image {image_path} not found, skipping.\")\n",
    "            continue\n",
    "\n",
    "        if 'result' not in data or not data['result']:\n",
    "            print(f\"image {image_path} has no annotations, skipping\")\n",
    "            continue\n",
    "\n",
    "        width = data['result'][0]['original_width']\n",
    "        height = data['result'][0]['original_height']\n",
    "\n",
    "        yolo_annotations = []\n",
    "        for annotation in data['result']:\n",
    "            label = annotation['value']['rectanglelabels'][0]\n",
    "            class_id = 0 if label == 'doctor' else 1  # Assuming 'doctor' is 0 and 'patient' is 1\n",
    "            x_center = (annotation['value']['x'] + annotation['value']['width'] / 2) / 100\n",
    "            y_center = (annotation['value']['y'] + annotation['value']['height'] / 2) / 100\n",
    "            w = annotation['value']['width'] / 100\n",
    "            h = annotation['value']['height'] / 100\n",
    "\n",
    "            yolo_annotations.append(f\"{class_id} {x_center} {y_center} {w} {h}\")\n",
    "\n",
    "        image_filename = data['task']['data']['image'].split('=')[1].replace('/', '%5C')\n",
    "        yolo_file_path = output_dir + \"/\" + f\"{os.path.splitext(image_filename)[0]}.txt\"\n",
    "        # yolo_file_path = os.path.join(output_dir, f\"{os.path.splitext(image_filename)[0]}.txt\")\n",
    "        print(yolo_file_path)\n",
    "        with open(yolo_file_path, 'w') as f:\n",
    "            f.write(\"\\n\".join(yolo_annotations))\n",
    "        \n",
    "        # Copy image to output directory\n",
    "        os.system(f\"cp {image_path} {output_dir}\")\n",
    "\n",
    "json_dir = 'LabeledDoctor'\n",
    "images_dir = 'DoctorImages'\n",
    "output_dir = 'AnnotationsYolo'\n",
    "\n",
    "convert_to_yolo_format(json_dir, images_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a37e7d-dd79-4c33-aadf-2206f8587026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import json\n",
    "\n",
    "def split_dataset(json_dir, image_dir, output_dir, split_ratio=0.8):\n",
    "    os.makedirs(os.path.join(output_dir, 'train', 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'train', 'labels'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'test', 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'test', 'labels'), exist_ok=True)\n",
    "    \n",
    "    json_files = [f for f in os.listdir(json_dir)]\n",
    "    # json_files = json_files.sort()\n",
    "    print(json_files)\n",
    "    random.shuffle(json_files)\n",
    "    # print(len(json_files))\n",
    "    \n",
    "    split_point = int(len(json_files) * split_ratio)\n",
    "    train_files = json_files[:split_point]\n",
    "    test_files = json_files[split_point:]\n",
    "    \n",
    "    return train_files, test_files\n",
    "\n",
    "json_dir = 'LabeledDoctor'\n",
    "image_dir = 'DoctorImages'\n",
    "output_dir = 'New_doctor_images'\n",
    "\n",
    "train_files, test_files = split_dataset(json_dir, image_dir, output_dir)\n",
    "print(train_files)\n",
    "print(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59442ba2-4c46-4e3e-8414-09868f646ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def convert_to_yolo_format(json_files, json_dir, image_dir, output_dir):\n",
    "    for json_file in json_files:\n",
    "        with open(os.path.join(json_dir, json_file)) as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        image_filename = data['task']['data']['image'].split('=')[1]\n",
    "        image_path = os.path.join(image_filename.replace('%5C', '/'))\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image {image_path} not found, skipping.\")\n",
    "            continue\n",
    "\n",
    "        if 'result' not in data or not data['result']:\n",
    "            print(f\"Image {image_path} has no annotations, skipping.\")\n",
    "            continue\n",
    "\n",
    "        width = data['result'][0]['original_width']\n",
    "        height = data['result'][0]['original_height']\n",
    "\n",
    "        yolo_annotations = []\n",
    "        for annotation in data['result']:\n",
    "            label = annotation['value']['rectanglelabels'][0]\n",
    "            class_id = 0 if label == 'doctor' else 1  # Assuming 'doctor' is 0 and 'patient' is 1\n",
    "            x_center = (annotation['value']['x'] + annotation['value']['width'] / 2) / 100\n",
    "            y_center = (annotation['value']['y'] + annotation['value']['height'] / 2) / 100\n",
    "            w = annotation['value']['width'] / 100\n",
    "            h = annotation['value']['height'] / 100\n",
    "\n",
    "            yolo_annotations.append(f\"{class_id} {x_center} {y_center} {w} {h}\")\n",
    "\n",
    "        image_filename = data['task']['data']['image'].split('=')[1].replace('/', '%5C')\n",
    "        yolo_file_path = os.path.join(output_dir, 'labels', f\"{os.path.splitext(image_filename)[0]}.txt\")\n",
    "        with open(yolo_file_path, 'w') as f:\n",
    "            f.write(\"\\n\".join(yolo_annotations))\n",
    "        \n",
    "        # Copy image to output directory\n",
    "        shutil.copy(image_path, os.path.join(output_dir, 'images', image_filename))\n",
    "\n",
    "\n",
    "json_dir = 'LabeledDoctor'\n",
    "image_dir = 'DoctorImages'\n",
    "output_dir = 'New_doctor_images'\n",
    "\n",
    "# Process training data\n",
    "train_output_dir = os.path.join(output_dir, 'train')\n",
    "convert_to_yolo_format(train_files, json_dir, image_dir, train_output_dir)\n",
    "\n",
    "# Process testing data\n",
    "test_output_dir = os.path.join(output_dir, 'test')\n",
    "convert_to_yolo_format(test_files, json_dir, image_dir, test_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a496af23-5eea-4bc0-9702-a9dd1f5c11b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = 'New_doctor_images/data.yaml'\n",
    "\n",
    "# Check if the data file exists\n",
    "if os.path.exists(data_path):\n",
    "    print(f\"{data_path} exists.\")\n",
    "else:\n",
    "    print(f\"{data_path} does not exist.\")\n",
    "\n",
    "# Check if train and val directories exist\n",
    "train_dir = 'New_doctor_images/train/images'\n",
    "val_dir = 'New_doctor_images/test/images'\n",
    "\n",
    "if os.path.exists(train_dir) and os.path.exists(val_dir):\n",
    "    print(\"Train and validation directories exist.\")\n",
    "else:\n",
    "    print(\"One or both directories do not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286dc5e6-59cd-425e-83fe-973ebd98ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "data_path = 'C:/Mini Project/Intel Project/datasets/New_doctor_images/data.yaml'\n",
    "print(f\"Data path: {os.path.abspath(data_path)}\")  # Print absolute path to data.yaml\n",
    "\n",
    "# Create a YOLOv8 model instance\n",
    "model = YOLO('yolov8n.pt')  # You can change 'n' to 's', 'm', 'l', or 'x' for larger models\n",
    "\n",
    "# Train the model\n",
    "model.train(data=data_path, epochs=50, imgsz=640, batch=8, name='yolov8_doctor_patient14')\n",
    "\n",
    "# Save the model\n",
    "model.save('yolov8_doctor_patient.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef8cc61-3f21-4105-9e11-891e1be4b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1d6b7b-27e7-4fac-a5d7-ab0a3d861259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Load the trained model\n",
    "model = YOLO('C:/Mini Project/Intel Project/runs/detect/yolov8_doctor_patient142/weights/best.pt')\n",
    "\n",
    "# Directory containing test images\n",
    "test_images_dir = 'C:/Mini Project/Intel Project/datasets/New_doctor_images/test/images'\n",
    "\n",
    "# List all test images\n",
    "test_images = [os.path.join(test_images_dir, img) for img in os.listdir(test_images_dir) if img.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Run predictions\n",
    "results = model.predict(source=test_images, conf=0.25, save=True, save_dir='predictions')\n",
    "\n",
    "# Display the results\n",
    "for result in results:\n",
    "    print(result)  # This will print the details of each prediction\n",
    "    result.show()  # This will display the image with predictions (requires GUI environment)\n",
    "\n",
    "# Evaluate the model on the validation dataset\n",
    "val_results = model.val()\n",
    "\n",
    "# Print evaluation results\n",
    "print(val_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3665fc3-3592-4c6d-9c19-63500691fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Load the trained model\n",
    "model = YOLO('C:/Mini Project/Intel Project/runs/detect/yolov8_doctor_patient142/weights/best.pt')\n",
    "\n",
    "# Directory containing test images\n",
    "test_images_dir = 'C:/Mini Project/Intel Project/ICU season 1/ep1'\n",
    "\n",
    "# List all test images\n",
    "test_images = [os.path.join(test_images_dir, img) for img in os.listdir(test_images_dir) if img.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Run predictions\n",
    "results = model.predict(source=test_images, conf=0.25, save=True, save_dir='ICU_predict1')\n",
    "\n",
    "# Display the results\n",
    "for result in results:\n",
    "    print(result)  # This will print the details of each prediction\n",
    "    result.show()  # This will display the image with predictions (requires GUI environment)\n",
    "\n",
    "# Evaluate the model on the validation dataset\n",
    "val_results = model.val()\n",
    "\n",
    "# Print evaluation results\n",
    "print(val_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "830bced5-56a1-48d1-b7c2-26a68fd6af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming all the files of icu folder\n",
    "# Function to rename multiple files\n",
    "import os\n",
    "\n",
    "def renaming():   \n",
    "    folder = \"ICU season 1\"\n",
    "    for count, filename in enumerate(os.listdir(folder)):\n",
    "        dst = f\"icu {str(count)}.jpg\"\n",
    "        src =f\"{folder}/{filename}\"  # foldername/filename, if .py file is outside folder\n",
    "        dst =f\"{folder}/{dst}\"\n",
    "         \n",
    "        # rename() function will\n",
    "        # rename all the files\n",
    "        os.rename(src, dst)\n",
    "\n",
    "renaming()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7185be0a-74cd-48d7-b62c-fb55e87208c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
