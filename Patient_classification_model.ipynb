{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jagdish9903/Intel-Project-TeleICU/blob/main/Patient_classification_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MH_3xcVfSNY",
        "outputId": "813f2f13-e4d6-426a-e39d-3ceda71c65e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.14 / client 1.6.12)\n",
            "Dataset URL: https://www.kaggle.com/datasets/sharjeelmazhar/human-activity-recognition-video-dataset\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "Downloading human-activity-recognition-video-dataset.zip to /content/drive/MyDrive/intel_proj\n",
            "100% 14.8G/14.8G [13:27<00:00, 21.0MB/s]\n",
            "100% 14.8G/14.8G [13:27<00:00, 19.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "#download human-action-classification-video-dataset\n",
        "!kaggle datasets download -d sharjeelmazhar/human-activity-recognition-video-dataset -p /content/drive/MyDrive/intel_proj/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install mediapipe package for keypoints detection\n",
        "!pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZR0fbdSoFun",
        "outputId": "4e4402dd-3ae4-437f-bcdc-bbad11945819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.7-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: protobuf, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.14 protobuf-4.25.3 sounddevice-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install yt-dlp to download youtube videos for testing\n",
        "!pip install yt-dlp\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "MqYPbLRQN1PN",
        "outputId": "92d356b5-b6e0-4532-beeb-1d239af782db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2024.7.7-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt-dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2024.6.2)\n",
            "Collecting mutagen (from yt-dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt-dlp)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests<3,>=2.32.2 (from yt-dlp)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
            "Collecting websockets>=12.0 (from yt-dlp)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.7)\n",
            "Installing collected packages: brotli, websockets, requests, pycryptodomex, mutagen, yt-dlp\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.20.0 requests-2.32.3 websockets-12.0 yt-dlp-2024.7.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              },
              "id": "f200255a410f48e48760990adb0fb301"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip the dataset\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/intel_proj/human-activity-recognition-video-dataset.zip'\n",
        "unzip_path = '/content/drive/MyDrive/intel_proj'\n",
        "\n",
        "with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(unzip_path)"
      ],
      "metadata": {
        "id": "mx0IgGP2gqHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import all dependencies\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import time\n",
        "import mediapipe as mp\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LSTM, Dropout, Dense\n",
        "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "y02McbR3ri6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp_holistic = mp.solutions.holistic # Holistic model for key-points detection\n",
        "mp_drawing = mp.solutions.drawing_utils # Drawing utilities to draw skeletons"
      ],
      "metadata": {
        "id": "yjcE74XprntM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#takes mediapipe model and video frame and outputs results and frame as it is\n",
        "def mediapipe_detection(image, model):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
        "    image.flags.writeable = False                  # Image is no longer writeable\n",
        "    results = model.process(image)                 # Make prediction\n",
        "    image.flags.writeable = True                   # Image is now writeable\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
        "    return image, results"
      ],
      "metadata": {
        "id": "G7JzxxH-rssS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#better visualizations of keypoints imposed on frames\n",
        "def draw_styled_landmarks(image, results):\n",
        "    # Draw face connections\n",
        "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
        "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
        "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
        "                             )\n",
        "    # Draw pose connections\n",
        "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
        "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
        "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
        "                             )\n",
        "    # Draw left hand connections\n",
        "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
        "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
        "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
        "                             )\n",
        "    # Draw right hand connections\n",
        "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
        "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
        "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
        "                             )"
      ],
      "metadata": {
        "id": "6Hy1JKNerv_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#create single vector for each frame detected keypoints and take zero if not detected\n",
        "def extract_keypoints(results):\n",
        "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
        "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
        "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
        "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
        "    return np.concatenate([pose, face, lh, rh])"
      ],
      "metadata": {
        "id": "Fn9EKxr8r2Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where your dataset is stored\n",
        "DATASET_PATH = os.path.join('drive','MyDrive','intel_proj','Human Activity Recognition - Video Dataset')\n",
        "\n",
        "# Path for exported data, numpy arrays\n",
        "DATA_PATH = os.path.join('drive','MyDrive','intel_proj','MP_Data')\n",
        "\n",
        "# Actions that we try to detect\n",
        "actions = np.array(['Clapping', 'Sitting', 'Standing Still','Walking'])"
      ],
      "metadata": {
        "id": "zsDBDULStp34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save extracted keypoints in .npy file to be used as dataset for classification model\n",
        "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
        "    # Loop through actions\n",
        "    for action in actions:\n",
        "        action_path = os.path.join(DATASET_PATH, action)\n",
        "        videos = os.listdir(action_path)[:70]  # List the first 70 video files in the action directory\n",
        "        # Loop through each video file\n",
        "        for sequence, video_file in enumerate(videos):\n",
        "            video_path = os.path.join(action_path, video_file)\n",
        "            cap = cv2.VideoCapture(video_path)\n",
        "            frame_num = 0\n",
        "            while cap.isOpened():\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                # Make detections\n",
        "                image, results = mediapipe_detection(frame, holistic)\n",
        "\n",
        "                # Export keypoints\n",
        "                keypoints = extract_keypoints(results)\n",
        "                npy_path = os.path.join(DATA_PATH, action, str(sequence), str(frame_num))\n",
        "                os.makedirs(os.path.dirname(npy_path), exist_ok=True)  # Create directory if it doesn't exist\n",
        "                np.save(npy_path, keypoints)\n",
        "\n",
        "                frame_num += 1\n",
        "\n",
        "                # Break gracefully\n",
        "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "                    break\n",
        "\n",
        "            cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "WUy2JbYivZgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results #visualize mediapipe output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAtYBwyswekB",
        "outputId": "a394a086-c2a0-43cf-85d7-abb127c14a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mediapipe.python.solution_base.SolutionOutputs"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.pose_landmarks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W4L7J_twfnc",
        "outputId": "1c0ea5f8-c2c5-4aee-907a-649976cc8214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "landmark {\n",
              "  x: 0.63159281\n",
              "  y: 0.180676371\n",
              "  z: -0.532001793\n",
              "  visibility: 0.999732673\n",
              "}\n",
              "landmark {\n",
              "  x: 0.65620482\n",
              "  y: 0.167847484\n",
              "  z: -0.509443343\n",
              "  visibility: 0.999354422\n",
              "}\n",
              "landmark {\n",
              "  x: 0.669236779\n",
              "  y: 0.168853045\n",
              "  z: -0.509680033\n",
              "  visibility: 0.999407053\n",
              "}\n",
              "landmark {\n",
              "  x: 0.678176701\n",
              "  y: 0.169411361\n",
              "  z: -0.509903193\n",
              "  visibility: 0.999448836\n",
              "}\n",
              "landmark {\n",
              "  x: 0.620464087\n",
              "  y: 0.16438815\n",
              "  z: -0.478037238\n",
              "  visibility: 0.99902451\n",
              "}\n",
              "landmark {\n",
              "  x: 0.609624743\n",
              "  y: 0.163290769\n",
              "  z: -0.477934211\n",
              "  visibility: 0.998809576\n",
              "}\n",
              "landmark {\n",
              "  x: 0.598394156\n",
              "  y: 0.162302405\n",
              "  z: -0.47779581\n",
              "  visibility: 0.998620629\n",
              "}\n",
              "landmark {\n",
              "  x: 0.700261354\n",
              "  y: 0.177263081\n",
              "  z: -0.303221792\n",
              "  visibility: 0.999623299\n",
              "}\n",
              "landmark {\n",
              "  x: 0.591125131\n",
              "  y: 0.168195903\n",
              "  z: -0.157532528\n",
              "  visibility: 0.996293724\n",
              "}\n",
              "landmark {\n",
              "  x: 0.651857376\n",
              "  y: 0.203220874\n",
              "  z: -0.447876185\n",
              "  visibility: 0.999778807\n",
              "}\n",
              "landmark {\n",
              "  x: 0.608891428\n",
              "  y: 0.200544417\n",
              "  z: -0.406840533\n",
              "  visibility: 0.999315\n",
              "}\n",
              "landmark {\n",
              "  x: 0.765698135\n",
              "  y: 0.268750757\n",
              "  z: -0.323355496\n",
              "  visibility: 0.999909163\n",
              "}\n",
              "landmark {\n",
              "  x: 0.528063655\n",
              "  y: 0.268635064\n",
              "  z: 0.20348528\n",
              "  visibility: 0.99725467\n",
              "}\n",
              "landmark {\n",
              "  x: 0.701487899\n",
              "  y: 0.404598504\n",
              "  z: -0.353244245\n",
              "  visibility: 0.989722192\n",
              "}\n",
              "landmark {\n",
              "  x: 0.474490196\n",
              "  y: 0.396686763\n",
              "  z: 0.152595207\n",
              "  visibility: 0.221363485\n",
              "}\n",
              "landmark {\n",
              "  x: 0.483436972\n",
              "  y: 0.335060894\n",
              "  z: -0.363861263\n",
              "  visibility: 0.984689951\n",
              "}\n",
              "landmark {\n",
              "  x: 0.421888888\n",
              "  y: 0.356901705\n",
              "  z: -0.345774114\n",
              "  visibility: 0.456626177\n",
              "}\n",
              "landmark {\n",
              "  x: 0.431336164\n",
              "  y: 0.315194309\n",
              "  z: -0.416598797\n",
              "  visibility: 0.965685189\n",
              "}\n",
              "landmark {\n",
              "  x: 0.395055711\n",
              "  y: 0.337521136\n",
              "  z: -0.42370066\n",
              "  visibility: 0.449717224\n",
              "}\n",
              "landmark {\n",
              "  x: 0.432907283\n",
              "  y: 0.293552667\n",
              "  z: -0.397328585\n",
              "  visibility: 0.963454306\n",
              "}\n",
              "landmark {\n",
              "  x: 0.395374119\n",
              "  y: 0.313698471\n",
              "  z: -0.454535782\n",
              "  visibility: 0.436571091\n",
              "}\n",
              "landmark {\n",
              "  x: 0.4508003\n",
              "  y: 0.301502496\n",
              "  z: -0.346641809\n",
              "  visibility: 0.94477427\n",
              "}\n",
              "landmark {\n",
              "  x: 0.420719\n",
              "  y: 0.321148187\n",
              "  z: -0.37796694\n",
              "  visibility: 0.413003623\n",
              "}\n",
              "landmark {\n",
              "  x: 0.65724659\n",
              "  y: 0.508026361\n",
              "  z: -0.125920728\n",
              "  visibility: 0.999443948\n",
              "}\n",
              "landmark {\n",
              "  x: 0.521655917\n",
              "  y: 0.503234208\n",
              "  z: 0.125584498\n",
              "  visibility: 0.998818457\n",
              "}\n",
              "landmark {\n",
              "  x: 0.623067379\n",
              "  y: 0.692689\n",
              "  z: -0.0925720483\n",
              "  visibility: 0.996120334\n",
              "}\n",
              "landmark {\n",
              "  x: 0.512962341\n",
              "  y: 0.684152365\n",
              "  z: 0.236549214\n",
              "  visibility: 0.986499429\n",
              "}\n",
              "landmark {\n",
              "  x: 0.595531881\n",
              "  y: 0.838741839\n",
              "  z: 0.565780461\n",
              "  visibility: 0.992972255\n",
              "}\n",
              "landmark {\n",
              "  x: 0.525892138\n",
              "  y: 0.83151263\n",
              "  z: 0.810538828\n",
              "  visibility: 0.989495933\n",
              "}\n",
              "landmark {\n",
              "  x: 0.603010774\n",
              "  y: 0.850609362\n",
              "  z: 0.613922179\n",
              "  visibility: 0.854065359\n",
              "}\n",
              "landmark {\n",
              "  x: 0.546803415\n",
              "  y: 0.846153617\n",
              "  z: 0.852373958\n",
              "  visibility: 0.915593505\n",
              "}\n",
              "landmark {\n",
              "  x: 0.550225139\n",
              "  y: 0.91216588\n",
              "  z: 0.283690363\n",
              "  visibility: 0.988062739\n",
              "}\n",
              "landmark {\n",
              "  x: 0.475636303\n",
              "  y: 0.904461741\n",
              "  z: 0.580610394\n",
              "  visibility: 0.987365961\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {label:num for num, label in enumerate(actions)} #create label maping for training"
      ],
      "metadata": {
        "id": "8e69w8iN3FW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yd1a1SpN3Gwm",
        "outputId": "850a7204-1987-4427-df5d-30574f4d48c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Clapping': 0, 'Sitting': 1, 'Standing Still': 2, 'Walking': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load saved dataset of .npy files\n",
        "sequences, labels = [], []\n",
        "for action in actions:\n",
        "    for sequence in np.array(os.listdir(os.path.join(DATA_PATH, action))).astype(int):\n",
        "        window = []\n",
        "        for frame_num in range(30):\n",
        "            file_path = os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num))\n",
        "            if os.path.isfile(file_path):\n",
        "                res = np.load(file_path)\n",
        "                window.append(res)\n",
        "        if len(window) == 30:  # Ensure only complete windows are added\n",
        "            sequences.append(window)\n",
        "            labels.append(label_map[action])"
      ],
      "metadata": {
        "id": "O3U_y2cc3IpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(sequences).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pnp8FpvCzsqi",
        "outputId": "a8c10b16-1f84-4617-a252-b8755216659e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(280, 30, 1662)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(labels).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiXwJ5tLz0YB",
        "outputId": "6c9fb4cd-0bad-4e9d-c702-176e1449fc92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(280,)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(sequences)"
      ],
      "metadata": {
        "id": "-NAvi1mLz4ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa-r6HWnz7PA",
        "outputId": "ee2d040b-8fa9-42de-ad21-014bd54bfa8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(280, 30, 1662)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one-hot encode labels\n",
        "y = tf.keras.utils.to_categorical(labels).astype(int)"
      ],
      "metadata": {
        "id": "Gx2YsCXIz-n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as080sjn2g2e",
        "outputId": "6f6f56c9-8b52-4dff-b8cb-8dd1734e6a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55, 200, 1662)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAcFDTRc6EWp",
        "outputId": "7b57cbdc-60b0-4455-c13e-3d41af411811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensorboard configuration to look over training process\n",
        "log_dir = os.path.join('Logs')\n",
        "tb_callback = TensorBoard(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "gJxaImpj6MeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir=Logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XArGzJjg6ni5",
        "outputId": "9100e0dc-1863-4a88-a61c-92e8678cc7b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-07 15:58:25.004003: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-07 15:58:25.004115: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-07 15:58:25.157970: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-07 15:58:28.152768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.15.2 at http://localhost:6006/ (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
      ],
      "metadata": {
        "id": "TqzK-6qA3ot-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create model architecture\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, input_shape=(30,1662)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))"
      ],
      "metadata": {
        "id": "ONN_h0Bs7WRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compile mode with necessary parameters\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VsEJxWtI7AKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#start training\n",
        "model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmdAjsYj7RAt",
        "outputId": "0e41668e-379b-44bb-c837-a80447afb6ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 4s 182ms/step - loss: 1.4346 - accuracy: 0.2782 - val_loss: 1.2665 - val_accuracy: 0.4286\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.3041 - accuracy: 0.3571 - val_loss: 1.1406 - val_accuracy: 0.5000\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 1.2677 - accuracy: 0.3684 - val_loss: 0.9964 - val_accuracy: 0.5714\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 1.2218 - accuracy: 0.4173 - val_loss: 1.0110 - val_accuracy: 0.5000\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 3s 299ms/step - loss: 1.2137 - accuracy: 0.4398 - val_loss: 1.0234 - val_accuracy: 0.7143\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 2s 250ms/step - loss: 1.2446 - accuracy: 0.3910 - val_loss: 1.0133 - val_accuracy: 0.7143\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 2s 184ms/step - loss: 1.2001 - accuracy: 0.4135 - val_loss: 0.9819 - val_accuracy: 0.7143\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 1.1793 - accuracy: 0.4436 - val_loss: 0.9455 - val_accuracy: 0.5714\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 1s 150ms/step - loss: 1.1241 - accuracy: 0.5000 - val_loss: 0.9179 - val_accuracy: 0.5714\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 1s 149ms/step - loss: 1.1225 - accuracy: 0.5000 - val_loss: 0.9147 - val_accuracy: 0.7857\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 1s 149ms/step - loss: 1.0927 - accuracy: 0.5188 - val_loss: 0.9370 - val_accuracy: 0.7857\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 1.0692 - accuracy: 0.5113 - val_loss: 0.8157 - val_accuracy: 0.6429\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 1s 162ms/step - loss: 1.0274 - accuracy: 0.5526 - val_loss: 0.8598 - val_accuracy: 0.7143\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 2s 220ms/step - loss: 0.9948 - accuracy: 0.5827 - val_loss: 0.7815 - val_accuracy: 0.7857\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.9048 - accuracy: 0.6429 - val_loss: 0.7978 - val_accuracy: 0.7143\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 1s 161ms/step - loss: 0.9923 - accuracy: 0.5940 - val_loss: 0.7811 - val_accuracy: 0.7143\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.0098 - accuracy: 0.5752 - val_loss: 0.6781 - val_accuracy: 0.9286\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9045 - accuracy: 0.6203 - val_loss: 0.7122 - val_accuracy: 0.7857\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8281 - accuracy: 0.7105 - val_loss: 0.6038 - val_accuracy: 0.7857\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7542 - accuracy: 0.7105 - val_loss: 0.5988 - val_accuracy: 0.8571\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6640 - accuracy: 0.7481 - val_loss: 0.4964 - val_accuracy: 0.8571\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6909 - accuracy: 0.7556 - val_loss: 0.4076 - val_accuracy: 0.9286\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6559 - accuracy: 0.7481 - val_loss: 0.3705 - val_accuracy: 0.9286\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6868 - accuracy: 0.7594 - val_loss: 0.6060 - val_accuracy: 0.7143\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5983 - accuracy: 0.7932 - val_loss: 0.2971 - val_accuracy: 0.9286\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5364 - accuracy: 0.8083 - val_loss: 0.3509 - val_accuracy: 0.9286\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5153 - accuracy: 0.8233 - val_loss: 0.2962 - val_accuracy: 0.9286\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 1s 134ms/step - loss: 0.5653 - accuracy: 0.8083 - val_loss: 0.3701 - val_accuracy: 0.9286\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 1s 159ms/step - loss: 0.5713 - accuracy: 0.8045 - val_loss: 0.3332 - val_accuracy: 0.9286\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 1s 162ms/step - loss: 0.5360 - accuracy: 0.8271 - val_loss: 0.4830 - val_accuracy: 0.7857\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 2s 172ms/step - loss: 0.5093 - accuracy: 0.8346 - val_loss: 0.2897 - val_accuracy: 0.9286\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.5047 - accuracy: 0.7932 - val_loss: 0.3202 - val_accuracy: 0.9286\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.4288 - accuracy: 0.8571 - val_loss: 0.3270 - val_accuracy: 0.9286\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4137 - accuracy: 0.8722 - val_loss: 0.2510 - val_accuracy: 0.9286\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3716 - accuracy: 0.8647 - val_loss: 0.2637 - val_accuracy: 0.9286\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.3514 - accuracy: 0.8910 - val_loss: 0.2016 - val_accuracy: 0.9286\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3919 - accuracy: 0.8647 - val_loss: 0.3309 - val_accuracy: 0.9286\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.3797 - accuracy: 0.8797 - val_loss: 0.2640 - val_accuracy: 0.9286\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.3778 - accuracy: 0.8722 - val_loss: 0.2009 - val_accuracy: 0.9286\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.3451 - accuracy: 0.8459 - val_loss: 0.2521 - val_accuracy: 0.9286\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4484 - accuracy: 0.8421 - val_loss: 0.3080 - val_accuracy: 0.8571\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4220 - accuracy: 0.8609 - val_loss: 0.3360 - val_accuracy: 0.9286\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4144 - accuracy: 0.8346 - val_loss: 0.2426 - val_accuracy: 0.9286\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 2s 167ms/step - loss: 0.3126 - accuracy: 0.8722 - val_loss: 0.2481 - val_accuracy: 0.8571\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 1s 165ms/step - loss: 0.2617 - accuracy: 0.9173 - val_loss: 0.2460 - val_accuracy: 0.9286\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 2s 174ms/step - loss: 0.2771 - accuracy: 0.8947 - val_loss: 0.2436 - val_accuracy: 0.9286\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.3522 - accuracy: 0.8872 - val_loss: 0.3482 - val_accuracy: 0.8571\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.2895 - accuracy: 0.9135 - val_loss: 0.2826 - val_accuracy: 0.9286\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.3431 - accuracy: 0.8759 - val_loss: 0.2219 - val_accuracy: 0.9286\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.3083 - accuracy: 0.8797 - val_loss: 0.2472 - val_accuracy: 0.9286\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e7a8dd72320>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "model.save('action_30.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fdfY8cm9CVr",
        "outputId": "d7919ad4-1304-41da-9289-1623fb405784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predict on test data\n",
        "yhat = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUikMPgx-FQh",
        "outputId": "0c192cb8-a9e2-4264-a6c7-13b488d7cbb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 468ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytrue = np.argmax(y_test, axis=1).tolist()\n",
        "yhat = np.argmax(yhat, axis=1).tolist()"
      ],
      "metadata": {
        "id": "KCcBKZ1u965L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#validate with confusion matrix\n",
        "multilabel_confusion_matrix(ytrue, yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5zKoH0x-Il-",
        "outputId": "4a56199a-8c10-4d37-95f3-a8e71a3f422c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[10,  0],\n",
              "        [ 0,  4]],\n",
              "\n",
              "       [[10,  1],\n",
              "        [ 0,  3]],\n",
              "\n",
              "       [[10,  0],\n",
              "        [ 1,  3]],\n",
              "\n",
              "       [[11,  0],\n",
              "        [ 0,  3]]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test accuracy\n",
        "accuracy_score(ytrue, yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q68jzA6K-MhX",
        "outputId": "353cf774-cb77-42c4-9755-311c340ddc26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9285714285714286"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download test video from youtube\n",
        "!yt-dlp -f mp4 -o \"download_walk.mp4\" \"https://youtube.com/shorts/LnYTAGmgphs?si=qXNH00sq4PkH3ncN\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK_OjPy9OS8x",
        "outputId": "d4e09870-470d-4a5c-bfaa-c5198404a01d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://youtube.com/shorts/LnYTAGmgphs?si=qXNH00sq4PkH3ncN\n",
            "[youtube] LnYTAGmgphs: Downloading webpage\n",
            "[youtube] LnYTAGmgphs: Downloading ios player API JSON\n",
            "[youtube] LnYTAGmgphs: Downloading m3u8 information\n",
            "[info] LnYTAGmgphs: Downloading 1 format(s): 18\n",
            "[download] download_walk.mp4 has already been downloaded\n",
            "\u001b[K[download] 100% of    1.15MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize the predicted class and its probability on output video\n",
        "def prob_viz(res, actions, input_frame, colors):\n",
        "    output_frame = input_frame.copy()\n",
        "    for num, prob in enumerate(res):\n",
        "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
        "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
        "\n",
        "    return output_frame"
      ],
      "metadata": {
        "id": "TTQRmZ1K-P-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load video\n",
        "model = tf.keras.models.load_model('/content/action_30.h5')"
      ],
      "metadata": {
        "id": "2qpaECarPXGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [(245, 117, 16), (117, 245, 16), (16, 117, 245),(255,0,0)]\n",
        "\n",
        "res = None\n",
        "image = None\n",
        "results = None\n",
        "action = None\n",
        "\n",
        "# Function to save video\n",
        "def save_video(input_path, output_path, model, actions, threshold=0.8):\n",
        "    # Initialize MediaPipe holistic model\n",
        "    mp_holistic = mp.solutions.holistic\n",
        "\n",
        "    # Capture video from the provided file path\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    # Define the codec and create VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Initialize sequence and sentence variables\n",
        "    sequence = []\n",
        "    sentence = []\n",
        "\n",
        "    with mp_holistic.Holistic(min_detection_confidence=0.3, min_tracking_confidence=0.3) as holistic:\n",
        "        frame_idx=0\n",
        "        media_idx = 0\n",
        "        while cap.isOpened():\n",
        "            global results\n",
        "            global image\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Make detections\n",
        "            if media_idx % 4 == 0:   #skip frames and transfer output of previous detection on undetected frames\n",
        "              image, results = mediapipe_detection(frame, holistic)\n",
        "\n",
        "            # Draw landmarks\n",
        "            draw_styled_landmarks(image, results)\n",
        "\n",
        "            # Prediction logic\n",
        "            keypoints = extract_keypoints(results)\n",
        "            sequence.append(keypoints)\n",
        "            sequence = sequence[-30:]\n",
        "\n",
        "            if len(sequence) == 30:   #take 30 frames window for prediction\n",
        "                global res\n",
        "                global action\n",
        "                if frame_idx % 4 == 0:\n",
        "                  res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
        "                  action = actions[np.argmax(res)]\n",
        "\n",
        "                # Viz logic\n",
        "                if res[np.argmax(res)] > threshold:\n",
        "                    if len(sentence) > 0:\n",
        "                        if action != sentence[-1]:\n",
        "                            sentence.append(action)\n",
        "                    else:\n",
        "                        sentence.append(action)\n",
        "\n",
        "                if len(sentence) > 5:\n",
        "                    sentence = sentence[-5:]\n",
        "\n",
        "                # Viz probabilities\n",
        "                image = prob_viz(res, actions, image, colors)\n",
        "\n",
        "                frame_idx += 1\n",
        "\n",
        "            # Add the sentence to the frame\n",
        "            cv2.rectangle(image, (0, 0), (640, 40), (245, 117, 16), -1)\n",
        "            cv2.putText(image, ' '.join(sentence), (3, 30),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "            # Write the frame to the output video\n",
        "            out.write(image)\n",
        "\n",
        "            media_idx += 1\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "# Path to input and output videos\n",
        "input_video_path = '/content/download_walk.mp4'\n",
        "output_video_path = 'vid_walk_gpu8.mp4'\n",
        "\n",
        "# Call the function to process the video\n",
        "save_video(input_video_path, output_video_path, model, actions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys3kNNy3H0tt",
        "outputId": "efebf542-5839-49be-b56a-6710667e9d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        }
      ]
    }
  ]
}